{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis: Real or Not? NLP with Disaster Tweets\n",
    "Melvin D. Macapinlac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "Twitter has become an important communication channel in times of emergency. The ubiquitousness of smartphones enables people to announce an emergency they’re observing in real-time. Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).\n",
    "\n",
    "But, it’s not always clear whether a person’s words are actually announcing a disaster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "The dataset was obtained from Kaggle. Each sample in the dataset has the following information:\n",
    "\n",
    "1. The `text` of a tweet\n",
    "2. A `keyword` from that tweet (although this may be blank!)\n",
    "3. The `location` the tweet was sent from (may also be blank)\n",
    "\n",
    "Here, the goal is to predict whether a given tweet is about a real disaster or not. If so, predict a `1`. If not, predict a `0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will compare the following:\n",
    "\n",
    "1. Sentiment Analysis by machine Learning classifier(either SVM or Naïve Bayes)\n",
    "2. Sentiment Analysis by opinion Lexicon\n",
    "              Adv+verb combination\n",
    "              Adj+adv+verb combination\n",
    "3. Compare the accuracy of Machine learning based SA with lexicon-based SA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Check distribution of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Sentiment_count=df.groupby('target').count()\n",
    "plt.bar(Sentiment_count.index.values, Sentiment_count['text'])\n",
    "plt.xlabel('Review Sentiments')\n",
    "plt.ylabel('Number of Review')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Sentiment Analysis by Machine Learning Classifier (NB) - Count Vectorizer\n",
    "For this model, we will use RegexpTokenizer to remove unwanted elements from the data like symbols and numbers. We will be converting the text to lowercase, remove stop words and tokenize the text by extracting unigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegexpTokenizer(pattern='[a-zA-Z0-9]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<7613x21295 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 80841 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "print(token)\n",
    "\n",
    "cv = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "\n",
    "text_counts= cv.fit_transform(df['text'])\n",
    "text_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    text_counts, df['target'], test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 0 0]\n",
      "MultinomialNB Accuracy: 0.7946584938704028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "predicted= clf.predict(X_test)\n",
    "print(predicted)\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Multinomial Naive Bayes with feature generation using Bag-of-Words, we got an accuracy of **79.47%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Sentiment Analysis by Machine Learning Classifier (NB) - TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf=TfidfVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "text_tf= tf.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    text_tf, df['target'], test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy: 0.803415061295972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "predicted= clf.predict(X_test)\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Multinomial Naive Bayes with feature generation using Bag-of-Words, we got an accuracy of **80.34%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Sentiment Analysis by Opinion Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def pos_lex_sentiment(lines, adj=True, verb=True, adverb=True):\n",
    "    \n",
    "    from nltk.corpus import opinion_lexicon\n",
    "    from nltk.tokenize import treebank\n",
    "    \n",
    "    tokenizer = treebank.TreebankWordTokenizer()\n",
    "    pos_words = 0\n",
    "    neg_words = 0\n",
    "    tokenized_sent = [word.lower() for word in tokenizer.tokenize(lines)]\n",
    "    part = nltk.pos_tag(tokenized_sent)\n",
    "    \n",
    "    new_text = []\n",
    "    if adj:\n",
    "        new_text.extend([p[0] for p in part if p[1].startswith('JJ')])\n",
    "    if verb:\n",
    "        new_text.extend([p[0] for p in part if p[1].startswith('VB')])\n",
    "    if adverb:\n",
    "        new_text.extend([p[0] for p in part if p[1].startswith('RB')])\n",
    "    if (not adj) and not verb and not adverb:\n",
    "        new_text.extend(tokenized_sent)\n",
    "    \n",
    "    y = []\n",
    "    for word in new_text:\n",
    "        if word in opinion_lexicon.positive():\n",
    "            pos_words += 1\n",
    "            y.append(1) #positive\n",
    "        elif word in opinion_lexicon.negative():\n",
    "            neg_words += 1\n",
    "            y.append(-1) #negative\n",
    "        else:\n",
    "            y.append(0) #neutral\n",
    "\n",
    "    if sum(y)==0:\n",
    "        return 0 # we consider this positive instead of neutral as the baseline does not contain neutral tweets\n",
    "    elif sum(y)<0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter only first 1000 rows for computational purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lex = df[:1000]\n",
    "df_lex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will try various POS combinations and compare the accuracy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Adverb + verb combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.674"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lex['adv_plus_verb'] = df_lex['text'].apply(pos_lex_sentiment, adj=False, verb=True, adverb=True)\n",
    "accuracy_score(df_lex['target'], df_lex['adv_plus_verb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Adjective + adverb + verb combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.656"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lex['adj_adv_verb'] = df_lex['text'].apply(pos_lex_sentiment, adj=True, verb=True, adverb=True)\n",
    "accuracy_score(df_lex['target'], df_lex['adj_adv_verb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.681"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lex['verb'] = df_lex['text'].apply(pos_lex_sentiment, adj=False, verb=True, adverb=False)\n",
    "accuracy_score(df_lex['target'], df_lex['verb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.669"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lex['adj'] = df_lex['text'].apply(pos_lex_sentiment, adj=True, verb=False, adverb=False)\n",
    "accuracy_score(df_lex['target'], df_lex['adj'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using machine learning classifiers, we are able to get a test accuracy of **79.47%** and **80.34%** accuracy, using bag of words and TFIDF vectorizer feature generation, respectively.\n",
    "\n",
    "Using Opinion Lexicon, we got the following results:\n",
    "    \n",
    "    a. adverb + verb combination = 67.4%\n",
    "    b. adjective + adverb + verb combination = 65.6%\n",
    "    c. verb only = 68.1%\n",
    "    d. adjective only = 66.9%\n",
    "    \n",
    "Overall, we got better results using the Multinomial Naive Bayes classifier. Results can be further improved with other data cleaning and preprocessing methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
